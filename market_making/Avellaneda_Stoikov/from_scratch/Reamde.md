# Avellaneda - Stoikov approch
### Текущий подход тестируется по данным ETHUSDT с дискретностью 1 мин


По модели Avellaneda-Stoikov делается расчет 
- резервированная цена
$$r = S_t -q\gamma\sigma^2(T-t)$$
- спред
$$\delta_a + \delta_b = \gamma\sigma^2(T-t) + \frac{1}{\gamma}\ln(1+\frac{\gamma}{k})$$

### Список параметров оптимизации (ищем RL методами)
- $\gamma$ - уровень аверсии (ниприятия) к риску
- k - параметр интенсивности сделок, который находится из соотношения $\lambda(\delta) = A\exp(-k\delta)$ ( если не находим этот параметр из реальных данных)
- $\Delta\sigma$ поправку в волатильность. Здесь мы принимаем, что $\sigma = \hat\sigma + \Delta\sigma$, где $\hat\sigma$ оценка волатильности из данных

### TODO:

#### Какие еще параметры можем оптимизировать
- T - время горизонта. Оптимизация как функция данных
- T = T(UTC time, day of week, day of year). Оптимизация как функция времени торгов
- $\Delta k$ поправку в параметр. Здесь мы принимаем, что $k = \hat{k} + \Delta k$, где $\hat{k}$ оценка параметра из данных

### Использование модели Метона со скачками (или других классов моделей) для более эффективного нахождения начальных условий
Для модели Мертона со скачками, дифференциальное уравнение и резервированная цена:

$$ dS_t = \mu dt +\sigma dW +JdN_t$$

$$r = S_t -q\gamma\sigma^2 (T-t) - \lambda \mathbb{E}[e^{-\gamma J} - 1](T-t)$$

## Av_Stoikov_RL
Решение первого приближения  
Оптимизируемые параметры
- $\gamma$
Задержка
- 1 мин
Алгортмы RL
- Deep Q Learning
- Actor Critic
